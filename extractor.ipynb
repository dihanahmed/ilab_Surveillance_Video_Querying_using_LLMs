{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0137628c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n"
     ]
    }
   ],
   "source": [
    "# If needed on your laptop:\n",
    "!pip install -q \"transformers>=4.41\" accelerate torch pandas tqdm huggingface_hub\n",
    "!pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ef5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "if not HF_TOKEN:\n",
    "    raise SystemExit(\"‚ùå Hugging Face token not found. Please set HF_TOKEN in .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ca0c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, time, csv\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# üîß EDIT this dataset path\n",
    "UCF_PATH = \"/Users/dihan_ahmed/DRIVE_1/UTS/4th semester/ilab/UCFCrime_Train.json\"\n",
    "\n",
    "ART_DIR = Path(\"artifacts\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ecbb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using: meta-llama/Llama-3.2-1B-Instruct | device: {'': 'mps'}\n"
     ]
    }
   ],
   "source": [
    "#Load Llama 3.2 1B Instruct model\n",
    "\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-1B-Instruct\"   # swap here if you try other models later\n",
    "\n",
    "# Prefer Apple Metal (MPS) on Mac; else CUDA; else CPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device_map = {\"\": \"mps\"}; torch_dtype = torch.float16\n",
    "elif torch.cuda.is_available():\n",
    "    device_map = \"auto\";      torch_dtype = torch.float16\n",
    "else:\n",
    "    device_map = None;        torch_dtype = torch.float32\n",
    "\n",
    "# Load tokenizer + model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=HF_TOKEN)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    token=HF_TOKEN,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device_map=device_map,\n",
    "    # attn_implementation=\"eager\",  # uncomment if you ever see MPS attention warnings\n",
    ")\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "print(\"‚úÖ Using:\", MODEL_ID, \"| device:\", device_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f9c3d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: [{'video_id': 'Abuse001_x264', 'sent_idx': 0, 'start': 0.0, 'end': 5.3, 'sentence': 'A woman with short hair, slightly fat, wearing a white top and black pants stood in front of the table, picked up a book from the table, and opened it to read'}, {'video_id': 'Abuse001_x264', 'sent_idx': 1, 'start': 7.0, 'end': 8.5, 'sentence': 'A man wearing a white shirt and black pants entered the house and walked towards the short-haired and fat woman in front who was reading a book.'}]\n"
     ]
    }
   ],
   "source": [
    "#dataset loader\n",
    "def load_ucf(path: str):\n",
    "    data = json.loads(Path(path).read_text(encoding=\"utf-8\"))\n",
    "    for vid, blob in data.items():\n",
    "        timestamps = blob.get(\"timestamps\", [])\n",
    "        sentences  = blob.get(\"sentences\", [])\n",
    "        for i, sent in enumerate(sentences):\n",
    "            ts = timestamps[i] if i < len(timestamps) else [None, None]\n",
    "            yield {\n",
    "                \"video_id\": vid,\n",
    "                \"sent_idx\": i,\n",
    "                \"start\": ts[0],\n",
    "                \"end\": ts[1],\n",
    "                \"sentence\": sent\n",
    "            }\n",
    "\n",
    "print(\"Sample:\", list(load_ucf(UCF_PATH))[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c70fdcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# promt schema\n",
    "SCHEMA_INSTRUCTIONS = \"\"\"Analyze the following annotation of a surveillance scene.\n",
    "Identify all people and objects. For each person/object, extract the following features:\n",
    "- attributes (clothes, clothes colour, looks, age, gender, posture, style, shoes),\n",
    "- actions (what they are doing),\n",
    "- interactions (who/what they interact with).\n",
    "\n",
    "Return ONLY a JSON array. Ensure all fields are present, even if empty.\n",
    "Keys: id, type (\"person\" or \"object\"), attributes[], actions[], interactions[].\n",
    "Rules:\n",
    "- If the text says \"woman/lady/girl\" include \"female\" in attributes; if \"man/boy\" include \"male\".\n",
    "- Do NOT put scene objects (house, table, road, ground, car, etc.) into person attributes.\n",
    "- Use \"unknown\" (in attributes) if gender is unclear.\n",
    "\"\"\"\n",
    "\n",
    "FEW_SHOT_INPUT = 'The woman wearing a red top holding a child walks in the direction of the woman in the couple.'\n",
    "FEW_SHOT_OUTPUT = [\n",
    "  {\"id\":\"person_1\",\"type\":\"person\",\"attributes\":[\"female\",\"red top\"],\n",
    "   \"actions\":[\"walking\",\"holding a child\"],\"interactions\":[\"child\"]}\n",
    "]\n",
    "\n",
    "def build_prompt(sentence: str) -> str:\n",
    "    return (\n",
    "        SCHEMA_INSTRUCTIONS\n",
    "        + \"\\nExample input:\\n\" + FEW_SHOT_INPUT\n",
    "        + \"\\nExample output:\\n\" + json.dumps(FEW_SHOT_OUTPUT, ensure_ascii=False)\n",
    "        + \"\\nNow extract for this input:\\n\" + sentence.strip()\n",
    "        + \"\\nOutput JSON array only:\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f873615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#strict JSON parser\n",
    "MAX_NEW_TOKENS = 280   # smaller ‚Üí faster; increase if you see truncation\n",
    "TEMPERATURE = 0.0\n",
    "TOP_P = 1.0\n",
    "REPETITION_PENALTY = 1.05\n",
    "RETRY_ATTEMPTS = 2\n",
    "RETRY_SLEEP = 0.25\n",
    "\n",
    "def _basic_repair(text: str) -> str:\n",
    "    \"\"\"Strip code fences, keep the outermost [...], and fix trailing commas & smart quotes.\"\"\"\n",
    "    t = text.strip()\n",
    "    t = re.sub(r\"^```json|```$\", \"\", t, flags=re.IGNORECASE|re.MULTILINE).strip()\n",
    "    s, e = t.find(\"[\"), t.rfind(\"]\")\n",
    "    if s != -1 and e != -1:\n",
    "        t = t[s:e+1]\n",
    "    t = t.replace(\"‚Äú\", '\"').replace(\"‚Äù\", '\"').replace(\"‚Äô\", \"'\")\n",
    "    t = re.sub(r\",\\s*]\", \"]\", t)\n",
    "    t = re.sub(r\",\\s*}\", \"}\", t)\n",
    "    return t\n",
    "\n",
    "def _parse_or_none(text: str):\n",
    "    t = _basic_repair(text)\n",
    "    try:\n",
    "        return json.loads(t)\n",
    "    except Exception:\n",
    "        m = re.search(r\"\\[[\\s\\S]*\\]\", t)\n",
    "        if m:\n",
    "            try:\n",
    "                return json.loads(m.group(0))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "def _normalize(items):\n",
    "    \"\"\"Ensure all keys exist with sensible defaults.\"\"\"\n",
    "    norm = []\n",
    "    for i, it in enumerate(items or []):\n",
    "        norm.append({\n",
    "            \"id\": it.get(\"id\", f\"item_{i}\"),\n",
    "            \"type\": it.get(\"type\", \"object\"),\n",
    "            \"attributes\": it.get(\"attributes\", []) or [],\n",
    "            \"actions\": it.get(\"actions\", []) or [],\n",
    "            \"interactions\": it.get(\"interactions\", []) or [],\n",
    "        })\n",
    "    return norm\n",
    "\n",
    "def call_llm(sentence: str):\n",
    "    \"\"\"Generate structured JSON for one sentence; retry if invalid JSON.\"\"\"\n",
    "    prompt = build_prompt(sentence)\n",
    "    for attempt in range(1 + RETRY_ATTEMPTS):\n",
    "        out = generator(\n",
    "            prompt,\n",
    "            max_new_tokens=MAX_NEW_TOKENS,\n",
    "            do_sample=False if TEMPERATURE==0 else True,\n",
    "            temperature=TEMPERATURE if TEMPERATURE>0 else None,\n",
    "            top_p=TOP_P,\n",
    "            repetition_penalty=REPETITION_PENALTY,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            return_full_text=False\n",
    "        )[0][\"generated_text\"]\n",
    "\n",
    "        # Some pipelines echo the prompt; trim if present\n",
    "        if out.strip().startswith(prompt.strip()):\n",
    "            out = out[len(prompt):].strip()\n",
    "\n",
    "        data = _parse_or_none(out)\n",
    "        if isinstance(data, list):\n",
    "            return _normalize(data)\n",
    "\n",
    "        # tighten instruction and retry\n",
    "        if attempt < RETRY_ATTEMPTS:\n",
    "            prompt = (\"Your previous answer was not valid JSON.\\n\"\n",
    "                      \"Respond with a STRICT JSON array only (no prose):\\n\") + prompt\n",
    "            time.sleep(RETRY_SLEEP)\n",
    "\n",
    "    print(\"JSON parse failed; returning []. Raw snippet:\\n\", out[:400])\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9903bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning and aggregation\n",
    "OBJECT_WORDS = {\n",
    "    \"house\",\"table\",\"ground\",\"road\",\"street\",\"sidewalk\",\"car\",\"van\",\"truck\",\"bus\",\n",
    "    \"motorbike\",\"bicycle\",\"bag\",\"umbrella\",\"bench\",\"chair\",\"door\",\"window\",\"wall\",\n",
    "    \"book\",\"ball\",\"sign\",\"badge\",\"license plate\",\"number plate\",\"store\",\"entrance\",\n",
    "    \"hallway\",\"parking\",\"lot\",\"weather\",\"rain\",\"snow\"\n",
    "}\n",
    "\n",
    "def _dedup_preserve_order(items):\n",
    "    seen = OrderedDict()\n",
    "    for x in items:\n",
    "        x = (x or \"\").strip()\n",
    "        if x and x not in seen:\n",
    "            seen[x] = True\n",
    "    return list(seen.keys())\n",
    "\n",
    "def aggregate_fields_for_sentence(extracted_items):\n",
    "    \"\"\"Merge attributes/actions/interactions across entities (gender remains in attributes).\"\"\"\n",
    "    attrs, acts, inters = [], [], []\n",
    "    for it in (extracted_items or []):\n",
    "        it_attrs = it.get(\"attributes\", []) or []\n",
    "        it_attrs = [a for a in it_attrs if a.lower().strip() not in OBJECT_WORDS]  # drop obvious objects\n",
    "        attrs.extend(it_attrs)\n",
    "        acts.extend(it.get(\"actions\", []) or [])\n",
    "        inters.extend(it.get(\"interactions\", []) or [])\n",
    "\n",
    "    attrs = _dedup_preserve_order(attrs)\n",
    "    acts  = _dedup_preserve_order(acts)\n",
    "    inters= _dedup_preserve_order(inters)\n",
    "\n",
    "    return \";\".join(attrs), \";\".join(acts), \";\".join(inters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f0c1526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected videos: ['Abuse001_x264', 'Abuse002_x264', 'Abuse003_x264', 'Abuse004_x264', 'Abuse005_x264', 'Abuse006_x264', 'Abuse007_x264', 'Abuse008_x264', 'Abuse009_x264', 'Abuse010_x264'] \n",
      "Model used: meta-llama/Llama-3.2-1B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse001_x264:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:55<01:33, 18.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  \n",
      "[{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"male\", \"white shirt\", \"black pants\"], \"actions\": [\"approached\", \"pulled out a piece of red cloth\"], \"interactions\": [\"woman\"]}] \n",
      "[{\"id\": \"person_3\", \"type\": \"person\", \"attributes\": [\"unknown\", \"short-haired\", \"fat woman\"], \"actions\": [\"not paying attention\"], \"interactions\": [\"woman\"]}] \n",
      "[{\"id\": \"object_4\", \"type\": \"object\", \"attributes\": [],\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse001_x264: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [01:16<00:00,  8.50s/it]\n",
      "Extracting Abuse002_x264:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 13/22 [01:23<02:11, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"vehicle_1\", \"type\": \"vehicle\", \"attributes\": [\"silver\", \"van\"], \"actions\": [\"driving\", \"opening the door\"], \"interactions\": [\"woman\", \"couple\", \"child\"]}] [{\"id\": \"vehicle_2\", \"type\": \"vehicle\", \"attributes\": [\"unknown\", \"unknown\"], \"actions\": [\"driving\"], \"interactions\": [\"woman\", \"couple\", \"child\"]}] [{\"id\": \"vehicle_3\", \"type\": \"vehicle\", \"attributes\": [\"unknown\", \"unknown\"], \"actions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse002_x264:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 14/22 [01:54<02:35, 19.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\"], \"actions\": [\"picks up\", \"child\"], \"interactions\": [\"child\"]}] {\"id\": \"person_3\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\"], \"actions\": [\"stands holding\", \"child\"], \"interactions\": [\"child\"]}] {\"id\": \"object_1\", \"type\": \"object\", \"attributes\": [], \"actions\": [\"picks up\", \"child\"], \"interactions\": [\"child\"]}] {\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse002_x264: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22/22 [02:51<00:00,  7.79s/it]\n",
      "Extracting Abuse003_x264:   4%|‚ñé         | 1/28 [00:32<14:40, 32.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"black short-sleeves\"], \"actions\": [\"pushed\"], \"interactions\": [\"old man\"]}] [{\"id\": \"person_3\", \"type\": \"person\", \"attributes\": [\"unknown\", \"long-sleeved top\"], \"actions\": [\"wearing a blanket\"], \"interactions\": [\"old man\"]}] [{\"id\": \"person_4\", \"type\": \"person\", \"attributes\": [\"unknown\", \"blanket\"], \"actions\": [\"covering his legs\"],\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse003_x264:  11%|‚ñà         | 3/28 [01:07<09:29, 22.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  \n",
      "[{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"black short-sleeves\"], \"actions\": [\"pushed\", \"bumped with the wheelchair\"], \"interactions\": [\"old man in the wheelchair\", \"wheelchair\"]}] \n",
      "[{\"id\": \"person_3\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\"], \"actions\": [\"unknown\"], \"interactions\": [\"unknown\"]}] \n",
      "[{\"id\": \"object_4\", \"type\": \"object\", \"attributes\": [], \"action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse003_x264:  14%|‚ñà‚ñç        | 4/28 [01:46<11:44, 29.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"object_1\", \"type\": \"object\", \"attributes\": [\"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unkn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse003_x264:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 16/28 [03:08<02:50, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"black short-sleeves\"], \"actions\": [\"pushed\", \"hit the wall with the wheelchair\"], \"interactions\": [\"old man\", \"wall\", \"wheelchair\"]}], [{\"id\": \"person_3\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\"], \"actions\": [\"unknown\"], \"interactions\": [\"old man\", \"wall\", \"wheelchair\"]}], [{\"id\": \"object_1\", \"type\": \"object\", \"attribu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse003_x264:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 22/28 [04:00<01:28, 14.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"person_1\", \"type\": \"person\", \"attributes\": [\"female\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unkno\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse003_x264:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 24/28 [04:42<01:18, 19.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unkn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse003_x264:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 26/28 [05:23<00:43, 21.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unkn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse003_x264: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [05:28<00:00, 11.72s/it]\n",
      "Extracting Abuse004_x264:  25%|‚ñà‚ñà‚ñå       | 16/64 [01:58<13:23, 16.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unkn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse004_x264:  30%|‚ñà‚ñà‚ñâ       | 19/64 [02:42<13:46, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  \n",
      "[{\"id\": \"object_1\", \"type\": \"object\", \"attributes\": [\"prisoner\"], \"actions\": [\"beaten\"], \"interactions\": [\"prisoner\"]}] \n",
      "[{\"id\": \"object_2\", \"type\": \"object\", \"attributes\": [\"prisoner\"], \"actions\": [\"kicked\"], \"interactions\": [\"prisoner\"]}] \n",
      "[{\"id\": \"object_3\", \"type\": \"object\", \"attributes\": [\"prisoner\"], \"actions\": [\"stopped\"], \"interactions\": [\"prisoner\"]}] \n",
      "[{\"id\": \"object_4\", \"type\": \"objec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse004_x264:  33%|‚ñà‚ñà‚ñà‚ñé      | 21/64 [03:24<15:16, 21.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  \n",
      "[{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse004_x264:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 58/64 [06:12<01:20, 13.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unkn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse004_x264: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 64/64 [06:36<00:00,  6.20s/it]\n",
      "Extracting Abuse005_x264: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:48<00:00,  4.06s/it]\n",
      "Extracting Abuse006_x264:  39%|‚ñà‚ñà‚ñà‚ñâ      | 15/38 [01:23<05:11, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  \n",
      "[{\"id\": \"object_1\", \"type\": \"object\", \"attributes\": [\"policeman\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse006_x264:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 27/38 [02:32<02:13, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  \n",
      "[{\"id\": \"policeman_1\", \"type\": \"person\", \"attributes\": [\"male\", \"unknown\"], \"actions\": [\"struggling\", \"rolling\"], \"interactions\": [\"police officer\", \"unknown\"]}] \n",
      "[{\"id\": \"policeman_2\", \"type\": \"person\", \"attributes\": [\"male\", \"unknown\"], \"actions\": [\"bending down\", \"holding him down\"], \"interactions\": [\"police officer\", \"unknown\"]}] \n",
      "[{\"id\": \"policeman_3\", \"type\": \"person\", \"attributes\": [\"male\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse006_x264: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 38/38 [02:53<00:00,  4.56s/it]\n",
      "Extracting Abuse007_x264:  36%|‚ñà‚ñà‚ñà‚ñå      | 5/14 [01:01<02:25, 16.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"object_1\", \"type\": \"object\", \"attributes\": [\"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unknown\", \"unkn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse007_x264: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14/14 [01:28<00:00,  6.30s/it]\n",
      "Extracting Abuse008_x264:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 12/29 [01:14<01:43,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\"], \"actions\": [\"pushed\", \"hard\"], \"interactions\": [\"prison\", \"woman\"]}] [{\"id\": \"person_3\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\"], \"actions\": [\"fell\", \"hit her head on the bed\"], \"interactions\": [\"woman\", \"prison\"]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse008_x264:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 19/29 [02:22<02:29, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"male\", \"book\"], \"actions\": [\"held a book\", \"bent down\"], \"interactions\": [\"woman\"]}] [{\"id\": \"person_3\", \"type\": \"person\", \"attributes\": [\"female\", \"hand\"], \"actions\": [\"leaned on the hand\"], \"interactions\": [\"woman\"]}] {\"id\": \"object_4\", \"type\": \"object\", \"attributes\": [], \"actions\": [\"ask\"], \"interactions\": [\"woman\"]} {\"id\": \"object_5\", \"typ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse008_x264: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [03:04<00:00,  6.36s/it]\n",
      "Extracting Abuse009_x264:  20%|‚ñà‚ñà        | 1/5 [00:32<02:09, 32.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  \n",
      "[{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\"], \"actions\": [\"standing\", \"holding a child\"], \"interactions\": [\"unknown\"]}] \n",
      "[{\"id\": \"person_3\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\"], \"actions\": [\"standing\", \"holding a child\"], \"interactions\": [\"unknown\"]}] \n",
      "[{\"id\": \"person_4\", \"type\": \"person\", \"attributes\": [\"unknown\", \"unknown\"], \"actions\": [\"standin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse009_x264: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:41<00:00,  8.28s/it]\n",
      "Extracting Abuse010_x264:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:38<00:40, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON parse failed; returning []. Raw snippet:\n",
      "  [{\"id\": \"person_2\", \"type\": \"person\", \"attributes\": [\"unknown\", \"curly hair\"], \"actions\": [\"ran\", \"raised her hand\"], \"interactions\": [\"puppy\", \"struggling puppy\"]}] [{\"id\": \"object_3\", \"type\": \"object\", \"attributes\": [], \"actions\": [\"ran\", \"struggled\"], \"interactions\": [\"puppy\"]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Abuse010_x264: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:46<00:00,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: artifacts/extracted_llama.json\n",
      "Wrote: artifacts/ucf_llm_featrures_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run extractor and save results\n",
    "LIMIT_VIDEOS = 10  # increase later\n",
    "\n",
    "# group rows by video\n",
    "by_vid = defaultdict(list)\n",
    "for r in load_ucf(UCF_PATH):\n",
    "    by_vid[r[\"video_id\"]].append(r)\n",
    "\n",
    "video_ids = list(by_vid.keys())[:LIMIT_VIDEOS]\n",
    "print(\"Selected videos:\", video_ids, \"\\nModel used:\", MODEL_ID)\n",
    "\n",
    "extracted_rows = []\n",
    "for vid in video_ids:\n",
    "    for row in tqdm(by_vid[vid], desc=f\"Extracting {vid}\"):\n",
    "        items = call_llm(row[\"sentence\"])\n",
    "        extracted_rows.append({**row, \"extracted\": items})\n",
    "\n",
    "# save full raw json (audit/debug)\n",
    "raw_json_path = ART_DIR / \"extracted_llama.json\"\n",
    "raw_json_path.write_text(json.dumps(extracted_rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"Wrote:\", raw_json_path)\n",
    "\n",
    "# save final CSV (gender is inside attributes)\n",
    "final_csv_path = ART_DIR / \"ucf_llm_featrures_2.csv\"   # <- your requested filename\n",
    "with final_csv_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"video\",\"scene_idx\",\"t_start\",\"t_end\",\"sentence\",\"attributes\",\"actions\",\"interactions\"])\n",
    "    for r in extracted_rows:\n",
    "        attributes, actions, interactions = aggregate_fields_for_sentence(r.get(\"extracted\", []))\n",
    "        writer.writerow([\n",
    "            r.get(\"video_id\",\"\"),\n",
    "            r.get(\"sent_idx\",\"\"),\n",
    "            r.get(\"start\",\"\"),\n",
    "            r.get(\"end\",\"\"),\n",
    "            r.get(\"sentence\",\"\"),\n",
    "            attributes,\n",
    "            actions,\n",
    "            interactions\n",
    "        ])\n",
    "\n",
    "print(\"Wrote:\", final_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9849c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>scene_idx</th>\n",
       "      <th>t_start</th>\n",
       "      <th>t_end</th>\n",
       "      <th>sentence</th>\n",
       "      <th>attributes</th>\n",
       "      <th>actions</th>\n",
       "      <th>interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>female;short hair;slightly fat</td>\n",
       "      <td>picking up a book;opening it to read</td>\n",
       "      <td>table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>A man wearing a white shirt and black pants en...</td>\n",
       "      <td>male;white shirt;black pants</td>\n",
       "      <td>entered the house;walked towards</td>\n",
       "      <td>short-haired and fat woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>A man wearing a black shirt and black pants en...</td>\n",
       "      <td>male;black shirt;black pants</td>\n",
       "      <td>entered the house;walked towards</td>\n",
       "      <td>short-haired and fat woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>A man wearing a white shirt and black pants ap...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>A man in black clothes approached a short-hair...</td>\n",
       "      <td>male;black clothes</td>\n",
       "      <td>punched the woman in the head</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>The woman fell to the ground in pain, and the ...</td>\n",
       "      <td>wooden;red</td>\n",
       "      <td>fell;knocked</td>\n",
       "      <td>table;book;woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>A woman with short hair and a fat figure weari...</td>\n",
       "      <td>female;short hair;fat figure</td>\n",
       "      <td>fell to the ground;raised her right hand to to...</td>\n",
       "      <td>table leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>7</td>\n",
       "      <td>15.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>unknown;short hair;slightly fat;white top;blac...</td>\n",
       "      <td>fell to the ground</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>25.4</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>unknown;short hair;slightly fat</td>\n",
       "      <td>kneel down;stand up</td>\n",
       "      <td>ground</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abuse002_x264</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>At an intersection with smooth traffic, the gr...</td>\n",
       "      <td>smooth;traffic;green light;vehicles on the opp...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           video  scene_idx  t_start  t_end  \\\n",
       "0  Abuse001_x264          0      0.0    5.3   \n",
       "1  Abuse001_x264          1      7.0    8.5   \n",
       "2  Abuse001_x264          2      7.2    8.5   \n",
       "3  Abuse001_x264          3      8.2    8.9   \n",
       "4  Abuse001_x264          4      8.9   11.2   \n",
       "5  Abuse001_x264          5      8.9   11.2   \n",
       "6  Abuse001_x264          6     11.3   13.3   \n",
       "7  Abuse001_x264          7     15.2   18.9   \n",
       "8  Abuse001_x264          8     19.7   25.4   \n",
       "9  Abuse002_x264          0      0.0    2.3   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  A woman with short hair, slightly fat, wearing...   \n",
       "1  A man wearing a white shirt and black pants en...   \n",
       "2  A man wearing a black shirt and black pants en...   \n",
       "3  A man wearing a white shirt and black pants ap...   \n",
       "4  A man in black clothes approached a short-hair...   \n",
       "5  The woman fell to the ground in pain, and the ...   \n",
       "6  A woman with short hair and a fat figure weari...   \n",
       "7  A woman with short hair, slightly fat, wearing...   \n",
       "8  A woman with short hair, slightly fat, wearing...   \n",
       "9  At an intersection with smooth traffic, the gr...   \n",
       "\n",
       "                                          attributes  \\\n",
       "0                     female;short hair;slightly fat   \n",
       "1                       male;white shirt;black pants   \n",
       "2                       male;black shirt;black pants   \n",
       "3                                                NaN   \n",
       "4                                 male;black clothes   \n",
       "5                                         wooden;red   \n",
       "6                       female;short hair;fat figure   \n",
       "7  unknown;short hair;slightly fat;white top;blac...   \n",
       "8                    unknown;short hair;slightly fat   \n",
       "9  smooth;traffic;green light;vehicles on the opp...   \n",
       "\n",
       "                                             actions  \\\n",
       "0               picking up a book;opening it to read   \n",
       "1                   entered the house;walked towards   \n",
       "2                   entered the house;walked towards   \n",
       "3                                                NaN   \n",
       "4                      punched the woman in the head   \n",
       "5                                       fell;knocked   \n",
       "6  fell to the ground;raised her right hand to to...   \n",
       "7                                 fell to the ground   \n",
       "8                                kneel down;stand up   \n",
       "9                                               none   \n",
       "\n",
       "                 interactions  \n",
       "0                       table  \n",
       "1  short-haired and fat woman  \n",
       "2  short-haired and fat woman  \n",
       "3                         NaN  \n",
       "4                       woman  \n",
       "5            table;book;woman  \n",
       "6                   table leg  \n",
       "7                       house  \n",
       "8                      ground  \n",
       "9                        none  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(final_csv_path)\n",
    "df.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
