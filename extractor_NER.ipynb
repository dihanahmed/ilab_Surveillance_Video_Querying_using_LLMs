{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4272db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-trf==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_trf-3.8.0/en_core_web_trf-3.8.0-py3-none-any.whl (457.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.4/457.4 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy-curated-transformers<1.0.0,>=0.2.2 in ./.venv/lib/python3.13/site-packages (from en-core-web-trf==3.8.0) (0.3.1)\n",
      "Requirement already satisfied: curated-transformers<0.2.0,>=0.1.0 in ./.venv/lib/python3.13/site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.1.1)\n",
      "Requirement already satisfied: curated-tokenizers<0.1.0,>=0.0.9 in ./.venv/lib/python3.13/site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (0.0.9)\n",
      "Requirement already satisfied: torch>=1.12.0 in ./.venv/lib/python3.13/site-packages (from spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2.8.0)\n",
      "Requirement already satisfied: regex>=2022 in ./.venv/lib/python3.13/site-packages (from curated-tokenizers<0.1.0,>=0.0.9->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.9.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.13/site-packages (from torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (2025.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch>=1.12.0->spacy-curated-transformers<1.0.0,>=0.2.2->en-core-web-trf==3.8.0) (3.0.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_trf')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -q spacy pandas tqdm\n",
    "\n",
    "!pip install -q spacy-transformers\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download en_core_web_trf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e216db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: /Users/dihan_ahmed/DRIVE_1/UTS/4th semester/ilab/UCFCrime_Train.json\n",
      "Outputs:\n",
      "artifacts/ner_plus/ucf_ner_plus_extracted.json\n",
      "artifacts/ner_plus/ucf_ner_plus_features.csv\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.matcher import Matcher\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ====== EDIT this to your JSON path ======\n",
    "UCF_PATH = \"/Users/dihan_ahmed/DRIVE_1/UTS/4th semester/ilab/UCFCrime_Train.json\"\n",
    "\n",
    "# Outputs (keep separate from your earlier run)\n",
    "OUT_DIR = Path(\"artifacts/ner_plus\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "JSON_OUT = OUT_DIR / \"ucf_ner_plus_extracted.json\"\n",
    "CSV_OUT  = OUT_DIR / \"ucf_ner_plus_features.csv\"\n",
    "\n",
    "# LLM CSV (optional: if present, a tiny eval will run at the end)\n",
    "LLM_CSV = Path(\"ucf_llm_featrures_2.csv\")\n",
    "\n",
    "# First 120 videos in file order\n",
    "LIMIT_VIDEOS = 120\n",
    "\n",
    "print(\"Dataset:\", UCF_PATH)\n",
    "print(\"Outputs:\", JSON_OUT, CSV_OUT, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34295ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos in file: 1165\n",
      "Processing first 120 videos (preserving input order).\n",
      "First 3 video ids: ['Abuse001_x264', 'Abuse002_x264', 'Abuse003_x264']\n"
     ]
    }
   ],
   "source": [
    "def load_ucf_in_order(path: str) -> \"OrderedDict[str, dict]\":\n",
    "    \"\"\"Load the UCFCrime JSON, preserving key order as written in file.\"\"\"\n",
    "    text = Path(path).read_text(encoding=\"utf-8\")\n",
    "    return json.loads(text, object_pairs_hook=OrderedDict)\n",
    "\n",
    "ucf = load_ucf_in_order(UCF_PATH)\n",
    "video_items = list(ucf.items())[:LIMIT_VIDEOS]\n",
    "print(f\"Total videos in file: {len(ucf)}\")\n",
    "print(f\"Processing first {len(video_items)} videos (preserving input order).\")\n",
    "print(\"First 3 video ids:\", [vid for vid, _ in video_items[:3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7412a81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EntityRuler patterns: 61\n"
     ]
    }
   ],
   "source": [
    "# Toggle: set to True to use the transformer model for better accuracy (slower)\n",
    "USE_TRANSFORMER = False\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\" if USE_TRANSFORMER else \"en_core_web_sm\")\n",
    "\n",
    "# -------- Domain lexicons (you can extend freely) ----------\n",
    "COLOR_WORDS = {\n",
    "    \"white\",\"black\",\"red\",\"green\",\"blue\",\"yellow\",\"pink\",\"purple\",\"orange\",\"grey\",\"gray\",\n",
    "    \"brown\",\"beige\",\"navy\",\"silver\"\n",
    "}\n",
    "CLOTHING_WORDS = {\n",
    "    \"shirt\",\"t-shirt\",\"tee\",\"top\",\"jacket\",\"coat\",\"hoodie\",\"sweater\",\"jumper\",\"dress\",\"skirt\",\n",
    "    \"pants\",\"trousers\",\"jeans\",\"shorts\",\"shoes\",\"sneakers\",\"boots\",\"sandals\",\n",
    "    \"cap\",\"hat\",\"scarf\",\"gloves\",\"belt\",\"bag\",\"backpack\",\"sleeves\",\"short-sleeves\",\"long-sleeves\"\n",
    "}\n",
    "PPE_WORDS = {\"helmet\",\"vest\",\"reflective\",\"hi-vis\",\"high-vis\"}\n",
    "VEHICLE_WORDS = {\"car\",\"van\",\"truck\",\"bus\",\"motorbike\",\"motorcycle\",\"bicycle\",\"bike\",\"scooter\"}\n",
    "\n",
    "PERSON_WORDS = {\n",
    "    \"man\",\"woman\",\"boy\",\"girl\",\"lady\",\"gentleman\",\"male\",\"female\",\"person\",\"people\",\n",
    "    \"policeman\",\"policewoman\",\"old man\",\"old woman\",\"young man\",\"young woman\"\n",
    "}\n",
    "\n",
    "# Scene objects we don't want as attributes\n",
    "OBJECT_STOP_IN_ATTRS = {\"table\",\"ground\",\"road\",\"street\",\"sidewalk\",\"door\",\"window\",\"house\",\"wall\",\"floor\"}\n",
    "\n",
    "# Synonym/normalization map\n",
    "SYN_MAP = {\n",
    "    \"t shirt\":\"t-shirt\",\"tee shirt\":\"t-shirt\",\"tee\":\"t-shirt\",\"t- shirt\":\"t-shirt\",\n",
    "    \"grey\":\"gray\",\"hi vis\":\"hi-vis\",\"high vis\":\"hi-vis\",\n",
    "    \"police man\":\"policeman\",\"police woman\":\"policewoman\",\n",
    "    \"short sleeves\":\"short-sleeves\",\"long sleeves\":\"long-sleeves\"\n",
    "}\n",
    "\n",
    "def norm_text(s: str) -> str:\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = SYN_MAP.get(s, s)\n",
    "    return s\n",
    "\n",
    "def dedup(seq: List[str]) -> List[str]:\n",
    "    seen = OrderedDict()\n",
    "    for x in seq:\n",
    "        x = (x or \"\").strip()\n",
    "        if x and x not in seen:\n",
    "            seen[x] = True\n",
    "    return list(seen.keys())\n",
    "\n",
    "# --------- EntityRuler to boost domain coverage ---------\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "\n",
    "patterns = []\n",
    "# Colors\n",
    "for w in COLOR_WORDS:\n",
    "    patterns.append({\"label\": \"COLOR\", \"pattern\": w})\n",
    "# PPE\n",
    "for w in PPE_WORDS:\n",
    "    patterns.append({\"label\": \"PPE\", \"pattern\": w})\n",
    "# Vehicles\n",
    "for w in VEHICLE_WORDS:\n",
    "    patterns.append({\"label\": \"VEHICLE\", \"pattern\": w})\n",
    "# Clothing (single words + common 2-token variants like 't shirt', 'short sleeves')\n",
    "for w in CLOTHING_WORDS:\n",
    "    if \" \" in w:\n",
    "        patterns.append({\"label\": \"CLOTHING\", \"pattern\": w})\n",
    "    else:\n",
    "        patterns.append({\"label\": \"CLOTHING\", \"pattern\": w})\n",
    "# Extra patterns for t-shirt variants\n",
    "patterns += [\n",
    "    {\"label\": \"CLOTHING\", \"pattern\": [{\"LOWER\": {\"IN\": [\"t\",\"t-\",\"tee\",\"tshirt\",\"t-shirt\"]}}, {\"LOWER\": {\"IN\": [\"shirt\",\"top\"]}}]},\n",
    "    {\"label\": \"CLOTHING\", \"pattern\": [{\"LOWER\": \"short\"}, {\"LOWER\": {\"IN\": [\"sleeve\",\"sleeves\"]}}]},\n",
    "    {\"label\": \"CLOTHING\", \"pattern\": [{\"LOWER\": \"long\"}, {\"LOWER\": {\"IN\": [\"sleeve\",\"sleeves\"]}}]},\n",
    "]\n",
    "ruler.add_patterns(patterns)\n",
    "print(\"EntityRuler patterns:\", len(patterns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ce50fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Phrasal verb pattern: VERB + PART (e.g., pick up, get out, fall down, lean over)\n",
    "matcher.add(\"PHRASAL_VERB\", [[{\"POS\":\"VERB\"},{\"POS\":\"PART\"}]])\n",
    "\n",
    "# Common surveillance verbs (lemma-based) for extra sensitivity\n",
    "COMMON_VERBS = [\n",
    "    \"walk\",\"run\",\"approach\",\"enter\",\"exit\",\"push\",\"pull\",\"pick\",\"hold\",\"carry\",\"open\",\"close\",\n",
    "    \"drive\",\"ride\",\"talk\",\"stand\",\"sit\",\"turn\",\"fall\",\"throw\",\"lift\",\"lean\",\"watch\",\"bump\",\"knock\",\"punch\",\n",
    "    \"kick\",\"grab\",\"drop\",\"kneel\",\"bend\",\"gesture\",\"move\"\n",
    "]\n",
    "for v in COMMON_VERBS:\n",
    "    matcher.add(f\"VERB_{v.upper()}\", [[{\"LEMMA\": v}]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80b26feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_gender_from_tokens(doc: spacy.tokens.Doc) -> str:\n",
    "    toks = {t.lemma_.lower() for t in doc if not t.is_space}\n",
    "    if {\"woman\",\"lady\",\"girl\",\"policewoman\",\"female\"} & toks:\n",
    "        return \"female\"\n",
    "    if {\"man\",\"gentleman\",\"boy\",\"policeman\",\"male\"} & toks:\n",
    "        return \"male\"\n",
    "    tset = {t.text.lower() for t in doc}\n",
    "    if \"she\" in tset or \"her\" in tset:\n",
    "        return \"female\"\n",
    "    if \"he\" in tset or \"his\" in tset:\n",
    "        return \"male\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def is_person_token(tok: spacy.tokens.Token) -> bool:\n",
    "    low = tok.lemma_.lower()\n",
    "    if tok.ent_type_ == \"PERSON\":\n",
    "        return True\n",
    "    if low in PERSON_WORDS:\n",
    "        return True\n",
    "    if tok.pos_ == \"PRON\" and tok.text.lower() in {\"he\",\"she\",\"they\",\"him\",\"her\"}:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def keep_reasonable(items: List[str], max_len: int = 48) -> List[str]:\n",
    "    out = []\n",
    "    for x in items:\n",
    "        x = norm_text(x)\n",
    "        if 0 < len(x) <= max_len and re.search(r\"[a-zA-Z]\", x):\n",
    "            out.append(x)\n",
    "    return dedup(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4594692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attributes(doc: spacy.tokens.Doc) -> List[str]:\n",
    "    attrs = []\n",
    "\n",
    "    # 1) Gender (per your schema it lives inside attributes)\n",
    "    g = infer_gender_from_tokens(doc)\n",
    "    if g: attrs.append(g)\n",
    "\n",
    "    # 2) From entities: colors, clothing, PPE\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in {\"COLOR\",\"CLOTHING\",\"PPE\"}:\n",
    "            attrs.append(norm_text(ent.text))\n",
    "\n",
    "    # 3) Person adjectives (e.g., 'short-haired woman' -> 'short-haired')\n",
    "    for t in doc:\n",
    "        if is_person_token(t):\n",
    "            for ch in t.lefts:\n",
    "                if ch.dep_ == \"amod\" and ch.pos_ == \"ADJ\":\n",
    "                    attrs.append(norm_text(ch.text))\n",
    "\n",
    "    # 4) Lexical fallback: color/clothing tokens (with compound/adjective modifiers)\n",
    "    for t in doc:\n",
    "        low = t.lemma_.lower()\n",
    "        if low in COLOR_WORDS or low in CLOTHING_WORDS:\n",
    "            chunk = t.text\n",
    "            mods = [m.text for m in t.lefts if m.dep_ in {\"amod\",\"compound\"} or m.lemma_.lower() in COLOR_WORDS]\n",
    "            if mods:\n",
    "                chunk = \" \".join([*mods, chunk])\n",
    "            attrs.append(norm_text(chunk))\n",
    "\n",
    "    # 5) Filter junk\n",
    "    attrs = [a for a in attrs if a not in OBJECT_STOP_IN_ATTRS]\n",
    "    return keep_reasonable(attrs)\n",
    "\n",
    "\n",
    "def extract_actions_interactions(doc: spacy.tokens.Doc) -> Tuple[List[str], List[str]]:\n",
    "    actions, interactions = [], []\n",
    "\n",
    "    # Optional: not used further here but can be leveraged for debugging/flags\n",
    "    _matches = matcher(doc)\n",
    "\n",
    "    for v in doc:\n",
    "        if v.pos_ != \"VERB\":\n",
    "            continue\n",
    "\n",
    "        # Person subject required\n",
    "        subj = [c for c in v.children if c.dep_ in {\"nsubj\",\"nsubjpass\"}]\n",
    "        if not any(is_person_token(s) for s in subj):\n",
    "            continue\n",
    "\n",
    "        # Build action phrase: lemma + particle + (first prep) + (first object head)\n",
    "        parts = [v.lemma_.lower()]\n",
    "\n",
    "        # Phrasal particle (pick up, get out, fall down, lean over)\n",
    "        prt = [c for c in v.children if c.dep_ == \"prt\"]\n",
    "        if prt:\n",
    "            parts.append(prt[0].text.lower())\n",
    "\n",
    "        # First preposition to compactly capture direction (e.g., 'toward', 'into')\n",
    "        prep_child = next((c for c in v.children if c.dep_ == \"prep\"), None)\n",
    "        if prep_child:\n",
    "            parts.append(prep_child.text.lower())\n",
    "\n",
    "        # Objects: direct + prepositional\n",
    "        objs = [c for c in v.children if c.dep_ in {\"dobj\",\"obj\"} and c.pos_ in {\"NOUN\",\"PROPN\"}]\n",
    "        if prep_child:\n",
    "            objs += [c for c in prep_child.children if c.dep_ == \"pobj\"]\n",
    "\n",
    "        obj_terms = []\n",
    "        for o in objs:\n",
    "            phrase = o.text.lower()\n",
    "            mods = [lc.text.lower() for lc in o.lefts if lc.dep_ in {\"compound\",\"amod\"}]\n",
    "            if mods:\n",
    "                phrase = \" \".join(mods + [phrase])\n",
    "            obj_terms.append(norm_text(phrase))\n",
    "\n",
    "        # Action phrase includes first object head when present\n",
    "        act = \" \".join(parts + ([obj_terms[0]] if obj_terms else []))\n",
    "        actions.append(act.strip())\n",
    "\n",
    "        # Interactions = all object terms for this verb\n",
    "        interactions.extend(obj_terms)\n",
    "\n",
    "    actions = keep_reasonable([a for a in actions if a and a != \"be\"])\n",
    "    interactions = keep_reasonable([x for x in interactions if x and x not in OBJECT_STOP_IN_ATTRS])\n",
    "    return actions, interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "395f7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence: str) -> Dict[str, List[str]]:\n",
    "    sentence = (sentence or \"\").strip()\n",
    "    if not sentence:\n",
    "        return {\"attributes\": [], \"actions\": [], \"interactions\": []}\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    attributes = extract_attributes(doc)\n",
    "    actions, interactions = extract_actions_interactions(doc)\n",
    "\n",
    "    # Ensure a gender token exists (fallback 'unknown')\n",
    "    if not any(g in attributes for g in (\"male\",\"female\",\"unknown\")):\n",
    "        attributes = [\"unknown\"] + attributes\n",
    "\n",
    "    return {\n",
    "        \"attributes\": dedup(attributes),\n",
    "        \"actions\": dedup(actions),\n",
    "        \"interactions\": dedup(interactions)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86b1d233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|██████████| 120/120 [00:04<00:00, 27.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows produced: 1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>scene_idx</th>\n",
       "      <th>t_start</th>\n",
       "      <th>t_end</th>\n",
       "      <th>sentence</th>\n",
       "      <th>attributes</th>\n",
       "      <th>actions</th>\n",
       "      <th>interactions</th>\n",
       "      <th>_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>female;white;top;black;pants;white top</td>\n",
       "      <td>stand in front</td>\n",
       "      <td>front</td>\n",
       "      <td>{'attributes': ['female', 'white', 'top', 'bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>A man wearing a white shirt and black pants en...</td>\n",
       "      <td>female;white;shirt;black;pants;haired;white shirt</td>\n",
       "      <td>enter house</td>\n",
       "      <td></td>\n",
       "      <td>{'attributes': ['female', 'white', 'shirt', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>A man wearing a black shirt and black pants en...</td>\n",
       "      <td>female;black;shirt;pants;haired;black shirt</td>\n",
       "      <td>enter house</td>\n",
       "      <td></td>\n",
       "      <td>{'attributes': ['female', 'black', 'shirt', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>A man wearing a white shirt and black pants ap...</td>\n",
       "      <td>female;white;shirt;black;pants;red;haired;fat;...</td>\n",
       "      <td>approach haired fat woman;pay attention;pull o...</td>\n",
       "      <td>haired fat woman;attention;piece;left side</td>\n",
       "      <td>{'attributes': ['female', 'white', 'shirt', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>A man in black clothes approached a short-hair...</td>\n",
       "      <td>female;black;white;top;pants;haired;fat;white top</td>\n",
       "      <td>approach haired fat woman;turn;punch in woman</td>\n",
       "      <td>haired fat woman;woman;head</td>\n",
       "      <td>{'attributes': ['female', 'black', 'white', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>The woman fell to the ground in pain, and the ...</td>\n",
       "      <td>female;red</td>\n",
       "      <td>fall to ground;fall;knock at red wooden table</td>\n",
       "      <td>red wooden table;same time</td>\n",
       "      <td>{'attributes': ['female', 'red'], 'actions': [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>A woman with short hair and a fat figure weari...</td>\n",
       "      <td>female;white;top;black;pants;white top</td>\n",
       "      <td>fall to ground</td>\n",
       "      <td></td>\n",
       "      <td>{'attributes': ['female', 'white', 'top', 'bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>7</td>\n",
       "      <td>15.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>female;white;top;black;pants;white top</td>\n",
       "      <td>fall to ground;touch with forehead;retract lef...</td>\n",
       "      <td>forehead;right hand;left leg</td>\n",
       "      <td>{'attributes': ['female', 'white', 'top', 'bla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           video  scene_idx  t_start  t_end  \\\n",
       "0  Abuse001_x264          0      0.0    5.3   \n",
       "1  Abuse001_x264          1      7.0    8.5   \n",
       "2  Abuse001_x264          2      7.2    8.5   \n",
       "3  Abuse001_x264          3      8.2    8.9   \n",
       "4  Abuse001_x264          4      8.9   11.2   \n",
       "5  Abuse001_x264          5      8.9   11.2   \n",
       "6  Abuse001_x264          6     11.3   13.3   \n",
       "7  Abuse001_x264          7     15.2   18.9   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  A woman with short hair, slightly fat, wearing...   \n",
       "1  A man wearing a white shirt and black pants en...   \n",
       "2  A man wearing a black shirt and black pants en...   \n",
       "3  A man wearing a white shirt and black pants ap...   \n",
       "4  A man in black clothes approached a short-hair...   \n",
       "5  The woman fell to the ground in pain, and the ...   \n",
       "6  A woman with short hair and a fat figure weari...   \n",
       "7  A woman with short hair, slightly fat, wearing...   \n",
       "\n",
       "                                          attributes  \\\n",
       "0             female;white;top;black;pants;white top   \n",
       "1  female;white;shirt;black;pants;haired;white shirt   \n",
       "2        female;black;shirt;pants;haired;black shirt   \n",
       "3  female;white;shirt;black;pants;red;haired;fat;...   \n",
       "4  female;black;white;top;pants;haired;fat;white top   \n",
       "5                                         female;red   \n",
       "6             female;white;top;black;pants;white top   \n",
       "7             female;white;top;black;pants;white top   \n",
       "\n",
       "                                             actions  \\\n",
       "0                                     stand in front   \n",
       "1                                        enter house   \n",
       "2                                        enter house   \n",
       "3  approach haired fat woman;pay attention;pull o...   \n",
       "4      approach haired fat woman;turn;punch in woman   \n",
       "5      fall to ground;fall;knock at red wooden table   \n",
       "6                                     fall to ground   \n",
       "7  fall to ground;touch with forehead;retract lef...   \n",
       "\n",
       "                                 interactions  \\\n",
       "0                                       front   \n",
       "1                                               \n",
       "2                                               \n",
       "3  haired fat woman;attention;piece;left side   \n",
       "4                 haired fat woman;woman;head   \n",
       "5                  red wooden table;same time   \n",
       "6                                               \n",
       "7                forehead;right hand;left leg   \n",
       "\n",
       "                                                _raw  \n",
       "0  {'attributes': ['female', 'white', 'top', 'bla...  \n",
       "1  {'attributes': ['female', 'white', 'shirt', 'b...  \n",
       "2  {'attributes': ['female', 'black', 'shirt', 'p...  \n",
       "3  {'attributes': ['female', 'white', 'shirt', 'b...  \n",
       "4  {'attributes': ['female', 'black', 'white', 't...  \n",
       "5  {'attributes': ['female', 'red'], 'actions': [...  \n",
       "6  {'attributes': ['female', 'white', 'top', 'bla...  \n",
       "7  {'attributes': ['female', 'white', 'top', 'bla...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows: List[Dict[str, Any]] = []\n",
    "\n",
    "for vid, blob in tqdm(video_items, desc=\"Processing videos\"):\n",
    "    timestamps = blob.get(\"timestamps\", [])\n",
    "    sentences  = blob.get(\"sentences\", [])\n",
    "    for i, sent in enumerate(sentences):\n",
    "        t0, t1 = (timestamps[i] if i < len(timestamps) else [None, None])\n",
    "        feats = process_sentence(sent)\n",
    "\n",
    "        rows.append({\n",
    "            \"video\": vid,\n",
    "            \"scene_idx\": i,\n",
    "            \"t_start\": t0,\n",
    "            \"t_end\": t1,\n",
    "            \"sentence\": sent,\n",
    "            # join lists for CSV (gender stays inside attributes)\n",
    "            \"attributes\": \";\".join(feats[\"attributes\"]),\n",
    "            \"actions\": \";\".join(feats[\"actions\"]),\n",
    "            \"interactions\": \";\".join(feats[\"interactions\"]),\n",
    "            # keep raw for JSON auditing\n",
    "            \"_raw\": feats\n",
    "        })\n",
    "\n",
    "print(\"Total rows produced:\", len(rows))\n",
    "pd.DataFrame(rows).head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ac7f065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote JSON: artifacts/ner_plus/ucf_ner_plus_extracted.json\n",
      "✅ Wrote CSV : artifacts/ner_plus/ucf_ner_plus_features.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>scene_idx</th>\n",
       "      <th>t_start</th>\n",
       "      <th>t_end</th>\n",
       "      <th>sentence</th>\n",
       "      <th>attributes</th>\n",
       "      <th>actions</th>\n",
       "      <th>interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>female;white;top;black;pants;white top</td>\n",
       "      <td>stand in front</td>\n",
       "      <td>front</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>A man wearing a white shirt and black pants en...</td>\n",
       "      <td>female;white;shirt;black;pants;haired;white shirt</td>\n",
       "      <td>enter house</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>A man wearing a black shirt and black pants en...</td>\n",
       "      <td>female;black;shirt;pants;haired;black shirt</td>\n",
       "      <td>enter house</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>A man wearing a white shirt and black pants ap...</td>\n",
       "      <td>female;white;shirt;black;pants;red;haired;fat;...</td>\n",
       "      <td>approach haired fat woman;pay attention;pull o...</td>\n",
       "      <td>haired fat woman;attention;piece;left side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>A man in black clothes approached a short-hair...</td>\n",
       "      <td>female;black;white;top;pants;haired;fat;white top</td>\n",
       "      <td>approach haired fat woman;turn;punch in woman</td>\n",
       "      <td>haired fat woman;woman;head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>11.2</td>\n",
       "      <td>The woman fell to the ground in pain, and the ...</td>\n",
       "      <td>female;red</td>\n",
       "      <td>fall to ground;fall;knock at red wooden table</td>\n",
       "      <td>red wooden table;same time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>A woman with short hair and a fat figure weari...</td>\n",
       "      <td>female;white;top;black;pants;white top</td>\n",
       "      <td>fall to ground</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>7</td>\n",
       "      <td>15.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>female;white;top;black;pants;white top</td>\n",
       "      <td>fall to ground;touch with forehead;retract lef...</td>\n",
       "      <td>forehead;right hand;left leg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abuse001_x264</td>\n",
       "      <td>8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>25.4</td>\n",
       "      <td>A woman with short hair, slightly fat, wearing...</td>\n",
       "      <td>female;white;top;black;pants;white top</td>\n",
       "      <td>sit on ground;turn head</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abuse002_x264</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>At an intersection with smooth traffic, the gr...</td>\n",
       "      <td>unknown;green;white</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           video  scene_idx  t_start  t_end  \\\n",
       "0  Abuse001_x264          0      0.0    5.3   \n",
       "1  Abuse001_x264          1      7.0    8.5   \n",
       "2  Abuse001_x264          2      7.2    8.5   \n",
       "3  Abuse001_x264          3      8.2    8.9   \n",
       "4  Abuse001_x264          4      8.9   11.2   \n",
       "5  Abuse001_x264          5      8.9   11.2   \n",
       "6  Abuse001_x264          6     11.3   13.3   \n",
       "7  Abuse001_x264          7     15.2   18.9   \n",
       "8  Abuse001_x264          8     19.7   25.4   \n",
       "9  Abuse002_x264          0      0.0    2.3   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  A woman with short hair, slightly fat, wearing...   \n",
       "1  A man wearing a white shirt and black pants en...   \n",
       "2  A man wearing a black shirt and black pants en...   \n",
       "3  A man wearing a white shirt and black pants ap...   \n",
       "4  A man in black clothes approached a short-hair...   \n",
       "5  The woman fell to the ground in pain, and the ...   \n",
       "6  A woman with short hair and a fat figure weari...   \n",
       "7  A woman with short hair, slightly fat, wearing...   \n",
       "8  A woman with short hair, slightly fat, wearing...   \n",
       "9  At an intersection with smooth traffic, the gr...   \n",
       "\n",
       "                                          attributes  \\\n",
       "0             female;white;top;black;pants;white top   \n",
       "1  female;white;shirt;black;pants;haired;white shirt   \n",
       "2        female;black;shirt;pants;haired;black shirt   \n",
       "3  female;white;shirt;black;pants;red;haired;fat;...   \n",
       "4  female;black;white;top;pants;haired;fat;white top   \n",
       "5                                         female;red   \n",
       "6             female;white;top;black;pants;white top   \n",
       "7             female;white;top;black;pants;white top   \n",
       "8             female;white;top;black;pants;white top   \n",
       "9                                unknown;green;white   \n",
       "\n",
       "                                             actions  \\\n",
       "0                                     stand in front   \n",
       "1                                        enter house   \n",
       "2                                        enter house   \n",
       "3  approach haired fat woman;pay attention;pull o...   \n",
       "4      approach haired fat woman;turn;punch in woman   \n",
       "5      fall to ground;fall;knock at red wooden table   \n",
       "6                                     fall to ground   \n",
       "7  fall to ground;touch with forehead;retract lef...   \n",
       "8                            sit on ground;turn head   \n",
       "9                                                      \n",
       "\n",
       "                                 interactions  \n",
       "0                                       front  \n",
       "1                                              \n",
       "2                                              \n",
       "3  haired fat woman;attention;piece;left side  \n",
       "4                 haired fat woman;woman;head  \n",
       "5                  red wooden table;same time  \n",
       "6                                              \n",
       "7                forehead;right hand;left leg  \n",
       "8                                        head  \n",
       "9                                              "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JSON: list of dicts (includes raw lists)\n",
    "JSON_OUT.write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# CSV: your project schema columns\n",
    "cols = [\"video\",\"scene_idx\",\"t_start\",\"t_end\",\"sentence\",\"attributes\",\"actions\",\"interactions\"]\n",
    "df = pd.DataFrame(rows)[cols]\n",
    "df.to_csv(CSV_OUT, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ Wrote JSON:\", JSON_OUT)\n",
    "print(\"✅ Wrote CSV :\", CSV_OUT)\n",
    "df.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
